{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mqp9gmB0o5qD"
      },
      "source": [
        "**Sprint 2    MODEL BUILDING**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tWeno1GT2vD7"
      },
      "source": [
        "**FOR BODY DAMAGE**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jMZFyuFHMVgI"
      },
      "source": [
        "1.Import The ImageDataGenerator Library"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "g8aOZz10MOpL",
        "outputId": "cecedf93-82c5-473e-8f3d-2400c0600fce"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ]
        }
      ],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Eb58fQKbMjTT",
        "outputId": "1ed98e31-b29a-4d8b-e7c5-60dfcdd1ab76"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "['body', 'level']\n"
          ]
        }
      ],
      "source": [
        "import os\n",
        "os.chdir(\"/content/drive/MyDrive\")\n",
        "Dataset = 'Car damage'\n",
        "Data_Dir=os.listdir(Dataset)\n",
        "print(Data_Dir)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Hu_pKZF5s_m3"
      },
      "outputs": [],
      "source": [
        "from tensorflow.keras.preprocessing.image import ImageDataGenerator"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "xC1eKS61sqFx"
      },
      "outputs": [],
      "source": [
        "train_datagen = ImageDataGenerator(rescale = 1./255,\n",
        "                                   shear_range = 0.1,\n",
        "                                   zoom_range = 0.1,\n",
        "                                   horizontal_flip = True)\n",
        "\n",
        "test_datagen = ImageDataGenerator(rescale = 1./255)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "RJJ7amW0sdks",
        "outputId": "42554abb-6ab6-4639-a433-ff524cd511c7"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ]
        }
      ],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "UeMFX4UT6oRn",
        "outputId": "e83718e1-6668-42d9-ce98-93a8558d55eb"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Found 979 images belonging to 3 classes.\n",
            "Found 171 images belonging to 3 classes.\n"
          ]
        }
      ],
      "source": [
        "training_set = train_datagen.flow_from_directory('/content/drive/MyDrive/Car damage/body/training',\n",
        "                                                 target_size=(224, 224),\n",
        "                                                 batch_size=10,\n",
        "                                                 class_mode='categorical')\n",
        "test_set = test_datagen.flow_from_directory('/content/drive/MyDrive/Car damage/body/validation',\n",
        "                                            target_size=(224, 224),\n",
        "                                            batch_size=10,\n",
        "                                            class_mode='categorical')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HshTN71rNLVt"
      },
      "source": [
        "**MODEL BUILDING**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "inl-ltCoNO-3"
      },
      "source": [
        "1.Importing The Model Building Libraries"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "kApn1AAmNRuQ"
      },
      "outputs": [],
      "source": [
        "from tensorflow.keras.layers import Dense,Flatten,Input\n",
        "from tensorflow.keras.models import Model\n",
        "from tensorflow.keras.preprocessing import image \n",
        "from tensorflow.keras.preprocessing.image import ImageDataGenerator,load_img\n",
        "from tensorflow.keras.applications.vgg16 import VGG16,preprocess_input\n",
        "from glob import glob\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kuHyshEOPI-U"
      },
      "source": [
        "2.Loading The Model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "KsmZOZCBQDar"
      },
      "outputs": [],
      "source": [
        "imagesize = [224, 224]\n",
        "\n",
        "train_path = '/content/drive/MyDrive/Intelligent Vehicle Damage Assessment & Cost Estimator For Insurance Companies/Dataset/body/training'\n",
        "valid_path = '/content/drive/MyDrive/Intelligent Vehicle Damage Assessment & Cost Estimator For Insurance Companies/Dataset/body/validation'"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Go4A9iexPQPn",
        "outputId": "649cf363-3e2d-4349-f8a9-b35a836201db"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Downloading data from https://storage.googleapis.com/tensorflow/keras-applications/vgg16/vgg16_weights_tf_dim_ordering_tf_kernels_notop.h5\n",
            "58889256/58889256 [==============================] - 0s 0us/step\n"
          ]
        }
      ],
      "source": [
        "#adding preprocessing Layers to the front of vgg\n",
        "\n",
        "vgg16 =VGG16(input_shape=imagesize + [3],weights='imagenet',include_top= False)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WAUVUs2KQd9e"
      },
      "source": [
        "3.Adding Flatten Layer"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "YNy0mlC5QfG_"
      },
      "outputs": [],
      "source": [
        "#don't train existing weights\n",
        "for layer in vgg16.layers:\n",
        "    layer.trainable = False"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "yxEz5JhLqRbZ"
      },
      "outputs": [],
      "source": [
        "folders=glob('/content/drive/MyDrive/Car damage/body/training/*')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-lGZ94iYqkTP",
        "outputId": "d1426e18-e733-44c1-f070-25f9e741126c"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "['/content/drive/MyDrive/Car damage/body/training/02-side',\n",
              " '/content/drive/MyDrive/Car damage/body/training/00-front',\n",
              " '/content/drive/MyDrive/Car damage/body/training/01-rear']"
            ]
          },
          "execution_count": 11,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "folders"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "QcJGWvyuRK9g"
      },
      "outputs": [],
      "source": [
        "#Our Layers -you can add more if you want\n",
        "x = Flatten()(vgg16.output)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qJm7gjCOqs0Z",
        "outputId": "b0382096-1c4b-40ef-e18a-6dcf580b794f"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "3"
            ]
          },
          "execution_count": 13,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "len(folders)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nbhqdVgGRpPf"
      },
      "source": [
        "4.Adding Output Layer"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "HcS0oBuNRs65"
      },
      "outputs": [],
      "source": [
        "prediction =Dense(len(folders),activation ='softmax')(x)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QoZ6sSMTR4qY"
      },
      "source": [
        "5.Creating A Model Object"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "67H4Jz9zR8dR"
      },
      "outputs": [],
      "source": [
        "# create a model object\n",
        "model =Model(inputs=vgg16.input, outputs=prediction)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "r0CchUy5SNUu",
        "outputId": "b51107ce-b565-40ec-e74d-cf555d1ab074"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Model: \"model\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " input_1 (InputLayer)        [(None, 224, 224, 3)]     0         \n",
            "                                                                 \n",
            " block1_conv1 (Conv2D)       (None, 224, 224, 64)      1792      \n",
            "                                                                 \n",
            " block1_conv2 (Conv2D)       (None, 224, 224, 64)      36928     \n",
            "                                                                 \n",
            " block1_pool (MaxPooling2D)  (None, 112, 112, 64)      0         \n",
            "                                                                 \n",
            " block2_conv1 (Conv2D)       (None, 112, 112, 128)     73856     \n",
            "                                                                 \n",
            " block2_conv2 (Conv2D)       (None, 112, 112, 128)     147584    \n",
            "                                                                 \n",
            " block2_pool (MaxPooling2D)  (None, 56, 56, 128)       0         \n",
            "                                                                 \n",
            " block3_conv1 (Conv2D)       (None, 56, 56, 256)       295168    \n",
            "                                                                 \n",
            " block3_conv2 (Conv2D)       (None, 56, 56, 256)       590080    \n",
            "                                                                 \n",
            " block3_conv3 (Conv2D)       (None, 56, 56, 256)       590080    \n",
            "                                                                 \n",
            " block3_pool (MaxPooling2D)  (None, 28, 28, 256)       0         \n",
            "                                                                 \n",
            " block4_conv1 (Conv2D)       (None, 28, 28, 512)       1180160   \n",
            "                                                                 \n",
            " block4_conv2 (Conv2D)       (None, 28, 28, 512)       2359808   \n",
            "                                                                 \n",
            " block4_conv3 (Conv2D)       (None, 28, 28, 512)       2359808   \n",
            "                                                                 \n",
            " block4_pool (MaxPooling2D)  (None, 14, 14, 512)       0         \n",
            "                                                                 \n",
            " block5_conv1 (Conv2D)       (None, 14, 14, 512)       2359808   \n",
            "                                                                 \n",
            " block5_conv2 (Conv2D)       (None, 14, 14, 512)       2359808   \n",
            "                                                                 \n",
            " block5_conv3 (Conv2D)       (None, 14, 14, 512)       2359808   \n",
            "                                                                 \n",
            " block5_pool (MaxPooling2D)  (None, 7, 7, 512)         0         \n",
            "                                                                 \n",
            " flatten (Flatten)           (None, 25088)             0         \n",
            "                                                                 \n",
            " dense (Dense)               (None, 3)                 75267     \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 14,789,955\n",
            "Trainable params: 75,267\n",
            "Non-trainable params: 14,714,688\n",
            "_________________________________________________________________\n"
          ]
        }
      ],
      "source": [
        "# view the structure of the model\n",
        "model.summary()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2zt2B4vXrnRv"
      },
      "source": [
        "6.Configure The Learning Process"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "y3TPL8dvSfUa"
      },
      "outputs": [],
      "source": [
        "#Compiling the CNN Model\n",
        "model.compile(\n",
        "  loss='categorical_crossentropy',\n",
        "  optimizer='adam',\n",
        "  metrics=['accuracy']\n",
        ")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "AIAYX6yYTCP0"
      },
      "source": [
        "7.Train the Model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "K9DSfxZy0TVp"
      },
      "outputs": [],
      "source": [
        "%%capture\n",
        "from time import sleep\n",
        "import random\n",
        "sleep(0.1)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vbqVtIptTFd_",
        "outputId": "ce4d5a30-26b6-49b8-dee1-c67272dbac40"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:8: UserWarning: `Model.fit_generator` is deprecated and will be removed in a future version. Please use `Model.fit`, which supports generators.\n",
            "  \n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 1/25\n",
            "98/98 [==============================] - 622s 6s/step - loss: 1.2631 - accuracy: 0.5271 - val_loss: 0.8213 - val_accuracy: 0.6842\n",
            "Epoch 2/25\n",
            "98/98 [==============================] - 615s 6s/step - loss: 0.7167 - accuracy: 0.7232 - val_loss: 0.9808 - val_accuracy: 0.6374\n",
            "Epoch 3/25\n",
            "98/98 [==============================] - 615s 6s/step - loss: 0.5639 - accuracy: 0.7794 - val_loss: 0.8704 - val_accuracy: 0.6667\n",
            "Epoch 4/25\n",
            "98/98 [==============================] - 611s 6s/step - loss: 0.3731 - accuracy: 0.8539 - val_loss: 1.2635 - val_accuracy: 0.5789\n",
            "Epoch 5/25\n",
            "98/98 [==============================] - 610s 6s/step - loss: 0.3092 - accuracy: 0.8907 - val_loss: 1.2483 - val_accuracy: 0.5965\n",
            "Epoch 6/25\n",
            "98/98 [==============================] - 608s 6s/step - loss: 0.3043 - accuracy: 0.8917 - val_loss: 1.0157 - val_accuracy: 0.6667\n",
            "Epoch 7/25\n",
            "98/98 [==============================] - 612s 6s/step - loss: 0.2238 - accuracy: 0.9254 - val_loss: 1.0529 - val_accuracy: 0.6667\n",
            "Epoch 8/25\n",
            "98/98 [==============================] - 609s 6s/step - loss: 0.1822 - accuracy: 0.9448 - val_loss: 1.0516 - val_accuracy: 0.6842\n",
            "Epoch 9/25\n",
            "98/98 [==============================] - 609s 6s/step - loss: 0.1530 - accuracy: 0.9551 - val_loss: 1.0432 - val_accuracy: 0.6959\n",
            "Epoch 10/25\n",
            "98/98 [==============================] - 609s 6s/step - loss: 0.1119 - accuracy: 0.9714 - val_loss: 1.2119 - val_accuracy: 0.6491\n",
            "Epoch 11/25\n",
            "98/98 [==============================] - 609s 6s/step - loss: 0.0984 - accuracy: 0.9714 - val_loss: 1.1495 - val_accuracy: 0.6725\n",
            "Epoch 12/25\n",
            "98/98 [==============================] - 608s 6s/step - loss: 0.1336 - accuracy: 0.9510 - val_loss: 1.2902 - val_accuracy: 0.6550\n",
            "Epoch 13/25\n",
            "98/98 [==============================] - 610s 6s/step - loss: 0.0860 - accuracy: 0.9796 - val_loss: 1.2168 - val_accuracy: 0.6725\n",
            "Epoch 14/25\n",
            "98/98 [==============================] - 609s 6s/step - loss: 0.0863 - accuracy: 0.9765 - val_loss: 1.2436 - val_accuracy: 0.6842\n",
            "Epoch 15/25\n",
            "98/98 [==============================] - 609s 6s/step - loss: 0.0607 - accuracy: 0.9888 - val_loss: 1.1402 - val_accuracy: 0.6901\n",
            "Epoch 16/25\n",
            "98/98 [==============================] - 610s 6s/step - loss: 0.0403 - accuracy: 0.9918 - val_loss: 1.3652 - val_accuracy: 0.6725\n",
            "Epoch 17/25\n",
            "98/98 [==============================] - 610s 6s/step - loss: 0.0754 - accuracy: 0.9765 - val_loss: 1.1864 - val_accuracy: 0.6550\n",
            "Epoch 18/25\n",
            "98/98 [==============================] - 611s 6s/step - loss: 0.0583 - accuracy: 0.9837 - val_loss: 1.2582 - val_accuracy: 0.6959\n",
            "Epoch 19/25\n",
            "98/98 [==============================] - 613s 6s/step - loss: 0.0630 - accuracy: 0.9877 - val_loss: 1.1300 - val_accuracy: 0.7135\n",
            "Epoch 20/25\n",
            "98/98 [==============================] - 615s 6s/step - loss: 0.0521 - accuracy: 0.9898 - val_loss: 1.3375 - val_accuracy: 0.6608\n",
            "Epoch 21/25\n",
            "98/98 [==============================] - 615s 6s/step - loss: 0.0599 - accuracy: 0.9898 - val_loss: 1.3451 - val_accuracy: 0.6901\n",
            "Epoch 22/25\n",
            "98/98 [==============================] - 617s 6s/step - loss: 0.1839 - accuracy: 0.9418 - val_loss: 1.6853 - val_accuracy: 0.6550\n",
            "Epoch 23/25\n",
            "98/98 [==============================] - 614s 6s/step - loss: 0.2020 - accuracy: 0.9254 - val_loss: 1.5183 - val_accuracy: 0.7018\n",
            "Epoch 24/25\n",
            "98/98 [==============================] - 611s 6s/step - loss: 0.0979 - accuracy: 0.9724 - val_loss: 1.3494 - val_accuracy: 0.6901\n",
            "Epoch 25/25\n",
            "98/98 [==============================] - 614s 6s/step - loss: 0.0467 - accuracy: 0.9908 - val_loss: 1.4229 - val_accuracy: 0.6959\n"
          ]
        }
      ],
      "source": [
        "import sys\n",
        "#fit the model\n",
        "r = model.fit_generator ( \n",
        "  training_set,\n",
        "  validation_data=test_set,\n",
        "  epochs=25,\n",
        "  steps_per_epoch=len(training_set),\n",
        "  validation_steps=len(test_set)\n",
        ")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "y5qN6fHf3vzH"
      },
      "source": [
        "8. Save The Model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "H3CbVQqa3hLR"
      },
      "outputs": [],
      "source": [
        "from tensorflow.keras.models import load_model\n",
        "\n",
        "model.save('body.h5')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zMmpOxTX2C_X"
      },
      "source": [
        "9. Test The Model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "nICzZ8iw2JZL"
      },
      "outputs": [],
      "source": [
        "from tensorflow.keras.models import load_model\n",
        "import cv2\n",
        "from skimage.transform import resize"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "SnKx5ltG2S5X"
      },
      "outputs": [],
      "source": [
        "model = load_model('body.h5')\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "cV13JhV44Mfd"
      },
      "outputs": [],
      "source": [
        "def detect(frame):\n",
        "  img = cv2.resize(frame,(224,224))\n",
        "  img = cv2.cvtColor(img,cv2.COLOR_BGR2RGB)\n",
        "\n",
        "  if(np.max(img)>1):\n",
        "    img = img/255.0\n",
        "  img = np.array([img])\n",
        "  prediction = model.predict(img)\n",
        "  label = [\"front\",\"rear\",\"side\"]\n",
        "  preds = label[np.argmax(prediction)]\n",
        "  return preds"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "uTq7I8Fc4Ndf"
      },
      "outputs": [],
      "source": [
        "import numpy as np"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "JMnAyCHe4TFi",
        "outputId": "707b3ecd-01a3-4dc5-9a1a-4e3f3871886d"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "1/1 [==============================] - 1s 1s/step\n",
            "front\n"
          ]
        }
      ],
      "source": [
        "data = \"/content/drive/MyDrive/Car damage/body/training/00-front/0010.JPEG\"\n",
        "image = cv2.imread(data)\n",
        "print(detect(image))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "uG4yzUtU3Zm8"
      },
      "source": [
        "**FOR LEVEL DAMAGE**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bf79F52Q3kTR"
      },
      "source": [
        "1. Import The ImageDataGenerator Library\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "0THfUV6N3dxN"
      },
      "outputs": [],
      "source": [
        "from tensorflow.keras.preprocessing.image import ImageDataGenerator"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qCshvHLr4A2B"
      },
      "source": [
        "2. Configure ImageDataGenerator Class"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "id": "vSPnbNRT4D01"
      },
      "outputs": [],
      "source": [
        "train_datagen = ImageDataGenerator(rescale = 1./255,\n",
        "                                   shear_range = 0.1,\n",
        "                                   zoom_range = 0.1,\n",
        "                                   horizontal_flip = True)\n",
        "\n",
        "test_datagen = ImageDataGenerator(rescale = 1./255)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rbQV18zK4MRA"
      },
      "source": [
        "3. Apply ImageDataGenerator Functionality To Trainset And Testset"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "FvITGFCI4NR9",
        "outputId": "59164b13-f926-4895-ac17-13f8afe932f2"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Found 979 images belonging to 3 classes.\n",
            "Found 171 images belonging to 3 classes.\n"
          ]
        }
      ],
      "source": [
        "training_set = train_datagen.flow_from_directory('/content/drive/MyDrive/Car damage/level/training',\n",
        "                                                 target_size = (224, 224),\n",
        "                                                 batch_size = 10,\n",
        "                                                 class_mode = 'categorical')\n",
        "test_set = test_datagen.flow_from_directory('/content/drive/MyDrive/Car damage/level/validation',\n",
        "                                            target_size = (224, 224),\n",
        "                                            batch_size = 10,\n",
        "                                            class_mode = 'categorical')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2nviJxed4sIk"
      },
      "source": [
        "MODEL BUILDING\n",
        "1. Importing The Model Building Libraries"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "VgVuAgid4t2y"
      },
      "outputs": [],
      "source": [
        "import tensorflow as tf\n",
        "from tensorflow.keras.layers import Input, Lambda, Dense, Flatten\n",
        "from tensorflow.keras.models import Model\n",
        "from tensorflow.keras.applications.vgg16 import VGG16\n",
        "from tensorflow.keras.applications.vgg19 import VGG19\n",
        "from tensorflow.keras.preprocessing import image\n",
        "from tensorflow.keras.preprocessing.image import ImageDataGenerator,load_img\n",
        "from tensorflow.keras.models import Sequential\n",
        "import numpy as np\n",
        "from glob import glob"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PeP7WCXT42PW"
      },
      "source": [
        "2. Loading The Model\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "id": "FrlQezVj40ww"
      },
      "outputs": [],
      "source": [
        "IMAGE_SIZE = [224, 224]\n",
        "\n",
        "train_path = '/content/drive/MyDrive/Car_damage/level/training'\n",
        "valid_path = '/content/drive/MyDrive/Car_damage/level/validation'"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xe-Ze0ad5AWn",
        "outputId": "ac48fed5-7b75-45ec-8f74-46314bb6f418"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading data from https://storage.googleapis.com/tensorflow/keras-applications/vgg16/vgg16_weights_tf_dim_ordering_tf_kernels_notop.h5\n",
            "58889256/58889256 [==============================] - 0s 0us/step\n"
          ]
        }
      ],
      "source": [
        "vgg16 = VGG16(input_shape=IMAGE_SIZE + [3], weights='imagenet', include_top=False)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8V-tT7j35Ev7"
      },
      "source": [
        "3. Adding Flatten Layer"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "id": "73PSEdwA5Fsa"
      },
      "outputs": [],
      "source": [
        "for layer in vgg16.layers:\n",
        "    layer.trainable = False"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "id": "jDCGXAGM5cUY"
      },
      "outputs": [],
      "source": [
        "folders = glob('/content/drive/MyDrive/Car damage/level/training/*')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "p4YpF3hP5iRj",
        "outputId": "ff8d281b-a467-4261-f340-ed5449890a34"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['/content/drive/MyDrive/Car damage/level/training/02-moderate',\n",
              " '/content/drive/MyDrive/Car damage/level/training/03-severe',\n",
              " '/content/drive/MyDrive/Car damage/level/training/01-minor']"
            ]
          },
          "metadata": {},
          "execution_count": 10
        }
      ],
      "source": [
        "folders"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "id": "osNc9cYk5tfl"
      },
      "outputs": [],
      "source": [
        "x = Flatten()(vgg16.output)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "08WPoAN65xHS",
        "outputId": "0e6df492-547c-40f9-b6d8-12cc5ded557d"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "3"
            ]
          },
          "metadata": {},
          "execution_count": 12
        }
      ],
      "source": [
        "len(folders)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "M1kIUySa53tZ"
      },
      "source": [
        "4. Adding Output Layer"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {
        "id": "5292QXZN518b"
      },
      "outputs": [],
      "source": [
        "prediction = Dense(len(folders), activation='softmax')(x)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BoPw22QB6OLg"
      },
      "source": [
        "5. Creating A Model Object"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {
        "id": "_v9-ZYOU6PeE"
      },
      "outputs": [],
      "source": [
        "model = Model(inputs=vgg16.input, outputs=prediction)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "KQ2KMV5G6WMi",
        "outputId": "14dfc58c-a719-444d-c730-edf872f501eb"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"model\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " input_1 (InputLayer)        [(None, 224, 224, 3)]     0         \n",
            "                                                                 \n",
            " block1_conv1 (Conv2D)       (None, 224, 224, 64)      1792      \n",
            "                                                                 \n",
            " block1_conv2 (Conv2D)       (None, 224, 224, 64)      36928     \n",
            "                                                                 \n",
            " block1_pool (MaxPooling2D)  (None, 112, 112, 64)      0         \n",
            "                                                                 \n",
            " block2_conv1 (Conv2D)       (None, 112, 112, 128)     73856     \n",
            "                                                                 \n",
            " block2_conv2 (Conv2D)       (None, 112, 112, 128)     147584    \n",
            "                                                                 \n",
            " block2_pool (MaxPooling2D)  (None, 56, 56, 128)       0         \n",
            "                                                                 \n",
            " block3_conv1 (Conv2D)       (None, 56, 56, 256)       295168    \n",
            "                                                                 \n",
            " block3_conv2 (Conv2D)       (None, 56, 56, 256)       590080    \n",
            "                                                                 \n",
            " block3_conv3 (Conv2D)       (None, 56, 56, 256)       590080    \n",
            "                                                                 \n",
            " block3_pool (MaxPooling2D)  (None, 28, 28, 256)       0         \n",
            "                                                                 \n",
            " block4_conv1 (Conv2D)       (None, 28, 28, 512)       1180160   \n",
            "                                                                 \n",
            " block4_conv2 (Conv2D)       (None, 28, 28, 512)       2359808   \n",
            "                                                                 \n",
            " block4_conv3 (Conv2D)       (None, 28, 28, 512)       2359808   \n",
            "                                                                 \n",
            " block4_pool (MaxPooling2D)  (None, 14, 14, 512)       0         \n",
            "                                                                 \n",
            " block5_conv1 (Conv2D)       (None, 14, 14, 512)       2359808   \n",
            "                                                                 \n",
            " block5_conv2 (Conv2D)       (None, 14, 14, 512)       2359808   \n",
            "                                                                 \n",
            " block5_conv3 (Conv2D)       (None, 14, 14, 512)       2359808   \n",
            "                                                                 \n",
            " block5_pool (MaxPooling2D)  (None, 7, 7, 512)         0         \n",
            "                                                                 \n",
            " flatten (Flatten)           (None, 25088)             0         \n",
            "                                                                 \n",
            " dense (Dense)               (None, 3)                 75267     \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 14,789,955\n",
            "Trainable params: 75,267\n",
            "Non-trainable params: 14,714,688\n",
            "_________________________________________________________________\n"
          ]
        }
      ],
      "source": [
        "model.summary()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "B8n5WUra6aVl"
      },
      "source": [
        "6. Configure The Learning Process"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "metadata": {
        "id": "Lceski9K6WGe"
      },
      "outputs": [],
      "source": [
        "model.compile(\n",
        "  loss='categorical_crossentropy',\n",
        "  optimizer='adam',\n",
        "  metrics=['accuracy']\n",
        ")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KKQdu52r6st0"
      },
      "source": [
        "8. Save The Model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 19,
      "metadata": {
        "id": "Mg-67Q5c6od7"
      },
      "outputs": [],
      "source": [
        "from tensorflow.keras.models import load_model\n",
        "\n",
        "model.save('level.h5')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "g8HGZTka6yf2"
      },
      "source": [
        "9. Test The Model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 20,
      "metadata": {
        "id": "vonnajrQ61lv"
      },
      "outputs": [],
      "source": [
        "from tensorflow.keras.models import load_model\n",
        "import cv2\n",
        "from skimage.transform import resize"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 21,
      "metadata": {
        "id": "dHRcXXQE6516"
      },
      "outputs": [],
      "source": [
        "model = load_model('level.h5')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 22,
      "metadata": {
        "id": "mTmNO2ps6_aD"
      },
      "outputs": [],
      "source": [
        "def detect(frame):\n",
        "  img = cv2.resize(frame,(224,224))\n",
        "  img = cv2.cvtColor(img,cv2.COLOR_BGR2RGB)\n",
        "\n",
        "  if(np.max(img)>1):\n",
        "    img = img/255.0\n",
        "  img = np.array([img])\n",
        "  prediction = model.predict(img)\n",
        "  label = [\"minor\",\"moderate\",\"severe\"]\n",
        "  preds = label[np.argmax(prediction)]\n",
        "  return preds"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 23,
      "metadata": {
        "id": "RUkUMC7X7F9N"
      },
      "outputs": [],
      "source": [
        "import numpy as np"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 25,
      "metadata": {
        "id": "JJBRJS7O7Kkl",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "c866f30b-b2b2-4833-9f94-b090c2718c2b"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1/1 [==============================] - 1s 797ms/step\n",
            "moderate\n"
          ]
        }
      ],
      "source": [
        "data = \"/content/drive/MyDrive/Car damage/level/validation/01-minor/0002.JPEG\"\n",
        "image = cv2.imread(data)\n",
        "print(detect(image))"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "collapsed_sections": [],
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}